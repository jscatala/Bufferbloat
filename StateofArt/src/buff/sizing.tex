Unmanaged buffers are more critical today since buffers sizes are larger, delay-sensitive applications are more prevalent, and large downloads common

buffers are essential to the proper functioning of packet networks, but overly large, unmanaged, and uncoordinated buffers create excessive delays that frustrate and baffle end users

Correct buffer sizing is not an easy problem. Undersizing - making buffers smaller than the traditional BDP- is fraught with problems. Today's links vary in bandwidth, and individual connections vary in rtt. This makes it impossible to properly pick a static size for most edge links. A simple, robust algorith that can manage buffer delay regardless of buffer size and link bandwidth without a negative impact on utilization can make oversized buffers irrelevant.


As we already know, all internet routers contains buffers to hold packets during times of congestion. A widely used rule-of-thumb states that each link need a buffer of size $B = \overline{RTT} x C $, where $\overline{RTT}$ is the average round trip time of a flow passing across the link, and C is the data rate of the link. The main characteristic of bufferbloat is the existence of excessively large and frequently full buffers inside the network. Large buffers have been inserted all over the Internet without sufficient thought or testing, so router buffers are the single biggest contributor to uncertainty in the Internet.\\

The rule-of-thumb come from a desire to keep the link as busy as possible so, the throughput of the network is always as big as possible. But, because the way that TCP works, no matter how big the buffer is at the bottleneck link, TCP will cause the buffer to overflow.\\ 

Overbuffering is a bad idea for two reasons:
\begin{enumerate}
\item It complicates the design of high-speed routers, leading to higher power consumption, more board space, and lower density.
\item It increases end-to-end delay in the presence of congestion
\end{enumerate}

The most important fact of sizing a buffer is to make that sure that while the sender pauses, the router buffer doesn't go empty and force the bottleneck to go idle. Again, the idea is to keep as much throughput as possible so the use of the link is fully utilized. The buffer will avoid to idle if the first packet from the sender shows up at the buffer just as it hits empty. In previous section, we define that after a lost is detected, the cwnd is set to half of is last value, so if we denote as $(W_{max} /2)/C$ the amount of time that packets are sent in congestion phase, and as $B/C$ the time that takes a buffer with size B to drain, the size of a buffer B needed is $B \leq (W_{max} /2)$.\\

Also from \cite{main:ref:1} and \cite{Vu-Brugier}, we can see that the rule-of-thumb doesn't longer apply to backbone routers, and a better estimator of the size of a buffer with n flows would be no more than $B = (\overline{RTT}xC)/\sqrt{n}$. With the assumption that short-flows plays a very small effect, and that the buffer size is dictated by the number of long flows, this factor will be proof that routers are much longer than they need to be, possible by two order of magnitude.


Since bandwidth can vary by a factor of 100 at shor time scales(ex move wirelessly), static buffers is never appropiate.

When does overbuffering hurt? Overbuffering hurts anytime you saturate a link. ex: copying a file over internet, VoIP, web Browsing

THe saturated link can be anywhere, in either or both directiosn in the path: easiest and most common to see is the operating system, wireless link, and broadband service.

Why is overbuffering a problem? oversized buffers fill and cause delay, destroying many uses of the Internet.

\textit{A TCP connection must react quickly to changes in demand at the bottleneck link, but TCP reaction time is quadratic to the amount of overbuffering}\cite{GettysNichols}.


At first, the equipement manufacturers believed that adding more buffers would be a good thing, primarily to handle increased traffic volumes to provide for fair access to capacity.

IF some manufacturer where to produce a home router with a very small buffer, data would get thrown away, and that manufacturer would very quickly get a reputation for making crummy routers. Then a comepertitor would be sure to say ``that router has a 90\% loss rate, so you want my box instead since it's got enough memory to avoid losing anything at all"

Unless you can get everybody to cooperate on reducing the buffers for every piece of equipment, the right strategy for any provider is to increase its buffer



while it's true that the larger the problem has to do with buffers that are too big, if you look at your own situation in therms of time rather than capacity and you can manage to double the performance on your link, then you ought to be able to cut your delay by half
