To test the existence of the Bufferbloat phenomenon, five tests are conducted 
as described below. Each test will be repeated under the following contexts:

\begin{enumerate}
\item Twice on the same day in one network to determine if does exist a 
considerable variance in latency for different times in a day.
\item Select different public and private networks with different 
\textit{``speeds''}.
\item Use the Ethernet cable in order to compare the results with those 
previously obtained using Wireless.
\end{enumerate}

Because it is intended to prove the existence of the phenomenon under
circumstances experienced by everyday users, no kernel parameters will be
amended nor changed, and only the  ability to perform QOS on routers that have
this feature is disabled.  Furthermore, the overall question these tests seek
to answer is the following:

\begin{theoremnon}[] 
``The networks that we use every day, have the necessary characteristics to
generate the  Bufferbloat phenomenon whether under low loads and if does
exists, the how  serious are the effects ?''
\end{theoremnon}

\subsubsection{Speed test} 
The idea under this test, is to set a baseline by comparing the speed offered 
by the ISP and the one at the moment of testing. To find the speed provided, 
the  tool used is the Speedtest in the web site of Ookla.

The benefits of using this web site is that not only it will reveal only
the available national uplink and downlink, also it will set the baseline
for the ping. The expected pings, independently of the connection bandwidth,
should be around $\sim12ms$, based on the data presented in \cite{netvtr} and
\cite{netmov} by the two most used ISP in Chile\footnote{Telef\'onica has a
39.2\% market share while VTR owns 38.8\% respectively. \cite{ispshares}}.

As data, it is estimated that the ratio of the average speed as compared to the
rated speed of the service offered for domestic bonds has a variation to 85\%,
while for international links decreases drastically to 35\%\cite{modcompqos}.
Due this factor, none of the tests will be performed on servers located outside
our country, as it is believed that the data will not very representative
regarding actual service.

\subsubsection{Signs of trouble} 
After characterize our network based on the
speed, it is needed to try to define the state of the service based on the
quality in which our network operates, in example: what kind of traffic is
passing through our network, and also get a little more detail on the
average rates of delay and buffers with which the traffic can find along the
path. To collect all this information will be used Netalyzr. 

While laws in Chile assure consumers networks free of traffic shaping
barriers and filters, ISPs apply traffic management
measures\cite{shapemov}\cite{shapevtr} to deliver an optimum experience of the
service's use and thus, achieve an efficient use of the network, thus further to
protect the safety of users while maintaining network stability.

This is why it is expected that some ports or services are partially or
completely blocked, but the most important is that this test will first light on
the existence of the phenomenon under study.

\subsubsection{Collapse test} 
Already having a clear idea of the state of the studied network, the next will
be try to check empirically that the results obtained by the previous test
above described are valid. For this, Iperf will be used to generate as much
traffic as possible for 5 minutes between servers. But the main goal is not to
measure the throughput of the network; instead to capture the packets that
Iperf produces and study them. So before run Iperf, tcpdump will capture this
information. Subsequently, the tcp's trace is taken and extracted with
tcptrace tool and generate the RTT graph.

This exercise will be conducted three times as part of the test, running the
first time as the sole source of network load. For the second and third time,
after 50 seconds after Iperf was started, from the Windows machine will be 
performed an upload to a Dropbox account with a file big enough to the upload 
take more than the time defined to this test. This upload intends to saturate 
the upstream link, leading to an overload of existing buffer (indistinct 
whether the server is national or not, there are several levels where the 
route is common). The upload will be stopped 50 seconds before the time limit.

The time gap established before loading and the end of the test is to let
Iperf frames reach a steady state flow and thus to generate a basis on which
to analyze the time when the traffic is maximum.

The expected RTT are around $\sim12ms$ and $\sim100ms$ without load, for
national and international servers respectively. About the expected value under
load, it is hard to estimate, further that their expected behavior is 
to be stable round a certain value. In case of no stable behavior, the possible 
causes will be analyzed and tracked.

\subsubsection{Load benchmark test}
With the effects of excess buffers already determined, this tests seeks to show
how this phenomenon affects users who surfs through a web browser. This is why
the extension of Google Chrome Page Benchmarker comes in and it will be used to
do 5 iterations of 10 loads to a website and analyze the behavior of these. 

As in the previous experiment, the first will be without any load on the
network. Then, again a file will be uploaded to Dropbox from the second machine
and after 30 seconds from the start of the load, and with the load active, will
proceed to a second iteration. The third will begin the after a minute,
canceling the file upload and after waiting 30 seconds after cancel the upload,
the benchmark will be measured again. The fourth and fifth will be a minute and
a half of a minute since the previous iteration have finished. The site chosen is
\url{http://www.usm.cl}.

As like Jim Gettys showed in his video demonstration\cite{gettysex}, the 
benchmark increases between 10 to 15 times with load against the original times. 
For this test, the expected proportions are lower, this mainly because the 
kernel machine that will run the tests has implemented already some improvements 
to mitigate this problem.

\subsubsection{Smoke the path}
To verify that the effect of Bufferbloat, if it is the case, does not just
happen on a single server or with a single TCP flow, the Smokeping tool will be
configured to perform two types of tests: Fping and echopinghttp. These tests
will be directed to different types of servers (ie: physical and VPS machines)
which have different connection settings and/or type of services (some servers
has dedicated link), and located in both Chile and the United States.

The tool will be left couple of minutes to track and save the state of the
connection under no extra load (only the test machine will be generating
data). After that, a upload of a big file will be performed from a second
machine until it finish or the behavior has become stable and then re-enter to
a phase without load for couple of more minutes and repeat the upload.

With this test, in addition to verifying the validity of the previously captured
data is expected to determine the presence of other factors that can contribute
to the degradation of the quality of service on the network, whether factors
such as quality of service provided by the host, channel/path problems, problems
related to the way handling packets by the router or the machine, and/or any
other that may arise.
